{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JY2oNJzF9E1y"
      },
      "source": [
        "#### Load and Resample Dataset\n",
        "\n",
        "The code below loads the data from Google Drive and resamples the data with 30 Hz."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "NORMAL_DATA_ID = \"13A6usZ2Agu2aCqUg2Ye6cDUied5x51gq\"\n",
        "CRASH_DATA_ID = \"1Os9E_WN8BaGKXA30kUrLn08dsnbM529h\""
      ],
      "metadata": {
        "id": "s5LS0SW7Drc7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f6gHZdvOgQXI"
      },
      "outputs": [],
      "source": [
        "from urllib.request import urlopen\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "load_data = lambda x: pd.read_csv(\n",
        "    urlopen(f'https://drive.google.com/uc?export=download&id={x}')\n",
        ").assign(\n",
        "    timestamp=lambda x: pd.TimedeltaIndex(x['timestamp'], unit='ms')\n",
        ").set_index(\n",
        "    'timestamp'\n",
        ").resample(\n",
        "    '33ms'\n",
        ").interpolate('linear').values\n",
        "\n",
        "NORMAL_DATA = load_data(NORMAL_DATA_ID)\n",
        "CRASH_DATA = load_data(CRASH_DATA_ID)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "HZ = 30\n",
        "print(NORMAL_DATA.shape)\n",
        "print(CRASH_DATA.shape)\n",
        "\n",
        "print(math.floor(NORMAL_DATA.shape[0]/HZ-1))\n",
        "print(math.floor(CRASH_DATA.shape[0]/HZ-1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5CP94zoeBO7d",
        "outputId": "b6a6f178-1bca-4020-90d5-f329d0495f0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(18398, 6)\n",
            "(18725, 6)\n",
            "612\n",
            "623\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xuIMyEXt_VF7"
      },
      "source": [
        "#### Split Data\n",
        "\n",
        "Here, we will use 90% of the whole data as the training data and remainings as the test data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LyKZCjpX_avY",
        "outputId": "9a26c965-5a8d-4211-c0d5-95d1dda43676"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train: (3638, 30, 6)\n",
            "X_test: (364, 30, 6)\n",
            "y_train: (3638,)\n",
            "y_test: (364,)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import random\n",
        "\n",
        "random.seed(1004)\n",
        "\n",
        "HZ = 30\n",
        "X, y = [], []\n",
        "X_train, y_train = [], []\n",
        "X_test, y_test = [], []\n",
        "\n",
        "for l, d, (secs_train, secs_test) in zip([0, 1], [NORMAL_DATA, CRASH_DATA], [(500, 600), (500, 600)]): # Label: 0 - Normal, 1 - Crash\n",
        "    count = 0\n",
        "    for i in np.arange(0, secs_test, 0.33):\n",
        "        s, e = int(i * HZ), int((i + 1) * HZ)\n",
        "        # print(s, e)\n",
        "        X.append(d[s:e, :])\n",
        "        count += 1\n",
        "    y.append(np.repeat(l, count))\n",
        "\n",
        "X, y = np.asarray(X), np.concatenate(y, axis=0)\n",
        "\n",
        "train_idxs = []\n",
        "test_idxs = []\n",
        "\n",
        "train_idx = random.sample(range(y.shape[0]), (int) (y.shape[0] * 9 / 10))\n",
        "train_idx = sorted(train_idx)\n",
        "\n",
        "test_idx = list(set(range(y.shape[0])) - set(train_idx))\n",
        "test_idx = sorted(test_idx)\n",
        "\n",
        "X_train, X_test = X, X[test_idx]\n",
        "y_train, y_test = y, y[test_idx]\n",
        "\n",
        "print(f'X_train: {X_train.shape}')\n",
        "print(f'X_test: {X_test.shape}')\n",
        "print(f'y_train: {y_train.shape}')\n",
        "print(f'y_test: {y_test.shape}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4r5sMPqkBdhf"
      },
      "source": [
        "#### Model Definition\n",
        "Define the model, using tensorflow keras.\n",
        "\n",
        "About the model structure, since the model extract features from data, it contains convolution layers.\n",
        "\n",
        "---\n",
        "```\n",
        "_________________________________________________________________\n",
        " Layer (type)                Output Shape              Param #\n",
        "=================================================================\n",
        " batch_normalization_3 (Batc  (None, 30, 6)            24\n",
        " hNormalization)\n",
        "\n",
        " conv1d_3 (Conv1D)           (None, 30, 32)            1568\n",
        "\n",
        " max_pooling1d_3 (MaxPooling  (None, 15, 32)           0\n",
        " 1D)\n",
        "\n",
        " flatten_3 (Flatten)         (None, 480)               0\n",
        "\n",
        " dense_6 (Dense)             (None, 64)                30784\n",
        "\n",
        " dropout_3 (Dropout)         (None, 64)                0\n",
        "\n",
        " dense_7 (Dense)             (None, 1)                 65\n",
        "\n",
        "=================================================================\n",
        "Total params: 32,441\n",
        "Trainable params: 32,429\n",
        "Non-trainable params: 12\n",
        "_________________________________________________________________\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TOtDpeBl__ok"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "\n",
        "model = keras.models.Sequential([\n",
        "      keras.layers.InputLayer(input_shape=(30, 6)),\n",
        "      keras.layers.BatchNormalization(),\n",
        "      keras.layers.Conv1D(\n",
        "          filters=32, kernel_size=8, padding = \"same\",\n",
        "          activation = keras.activations.relu,\n",
        "          kernel_initializer=keras.initializers.HeNormal(seed=1004),\n",
        "      ),\n",
        "      keras.layers.MaxPooling1D(\n",
        "          pool_size=2\n",
        "      ),\n",
        "      keras.layers.Flatten(),\n",
        "      keras.layers.Dense(\n",
        "          units = 64,\n",
        "          activation = keras.activations.relu,\n",
        "          kernel_initializer = keras.initializers.HeNormal(seed=1004)\n",
        "      ),\n",
        "      keras.layers.Dropout(\n",
        "          rate = .5,\n",
        "      ),\n",
        "      keras.layers.Dense(\n",
        "          units = 1,\n",
        "          activation=keras.activations.sigmoid,\n",
        "          kernel_initializer=keras.initializers.GlorotUniform(seed=1004)\n",
        "      )\n",
        "  ])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Model Training\n",
        "Now compile and train the defined model.\n",
        "\n",
        "As our model classifies the crash, we will use a binary crossentropy  as the loss function."
      ],
      "metadata": {
        "id": "CG_-TFIBG9e_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "\n",
        "model.compile(\n",
        "    loss=keras.losses.BinaryCrossentropy (),\n",
        "    optimizer=keras.optimizers.Adam(),\n",
        "    metrics=[\n",
        "            keras.metrics.BinaryAccuracy(),\n",
        "    ]\n",
        ")\n",
        "\n",
        "model.fit(\n",
        "    x=X_train,\n",
        "    y=y_train,\n",
        "    validation_data=(X_test, y_test),\n",
        "    batch_size=64,\n",
        "    epochs=2,\n",
        ")"
      ],
      "metadata": {
        "id": "tEIEKPWVG9M9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f10013c3-daf3-49e9-f5ca-abf21f5f3087"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "57/57 [==============================] - 2s 10ms/step - loss: 0.1420 - binary_accuracy: 0.9511 - val_loss: 0.0235 - val_binary_accuracy: 0.9973\n",
            "Epoch 2/2\n",
            "57/57 [==============================] - 0s 7ms/step - loss: 0.0273 - binary_accuracy: 0.9964 - val_loss: 0.0213 - val_binary_accuracy: 0.9973\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0f112352a0>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6pRHYACmBCCW"
      },
      "source": [
        "#### Evaluation\n",
        "Now using the test data, evaluate our model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "arNAcZHNBE3p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23afffb3-2e69-4ecf-9bc8-8522e334198f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12/12 [==============================] - 0s 2ms/step\n",
            "12/12 [==============================] - 0s 3ms/step\n",
            "Accuracy: 99.73 %.\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "y_pred = np.argmax(model.predict(X_test), axis=1)\n",
        "y_pred = np.round(model.predict(X_test))\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(f'Accuracy: {acc * 100:.2f} %.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sJNcrgjMv-tS"
      },
      "source": [
        "#### Deployment\n",
        "Now with the tensorflow, deploy our model as .tf model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ea4889f-3669-4827-85f5-e3254ed16183",
        "id": "V05wqM9Zv-tU"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _update_step_xla while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "tf.saved_model.save(model, \"saved_model_keras_dir\")\n",
        "\n",
        "# Convert the model\n",
        "converter = tf.lite.TFLiteConverter.from_saved_model(\"saved_model_keras_dir\") # path to the SavedModel directory\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "# Save the model.\n",
        "with open('model.tflite', 'wb') as f:\n",
        "  f.write(tflite_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QiOdmsxA_KTT"
      },
      "source": [
        "#### K-Fold Validation (K=10)\n",
        "\n",
        "Here, we will use data for first {x} jumps as training data and remainings as test data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nQ8UJ-M7_KTV"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import random\n",
        "\n",
        "random.seed(1004)\n",
        "\n",
        "HZ = 30\n",
        "X, y = [], []\n",
        "X_train, y_train = [], []\n",
        "X_test, y_test = [], []\n",
        "\n",
        "for l, d, (secs_train, secs_test) in zip([0, 1], [NORMAL_DATA, CRASH_DATA], [(500, 600), (500, 600)]): # Label: 0 - Normal, 1 - Crash\n",
        "    count = 0\n",
        "    for i in np.arange(0, secs_test, 0.33):\n",
        "        s, e = int(i * HZ), int((i + 1) * HZ)\n",
        "        # print(s, e)\n",
        "        X.append(d[s:e, :])\n",
        "        count += 1\n",
        "    y.append(np.repeat(l, count))\n",
        "\n",
        "X, y = np.asarray(X), np.concatenate(y, axis=0)\n",
        "\n",
        "train_idxs = []\n",
        "test_idxs = []\n",
        "\n",
        "for fold in range(10):\n",
        "    mother_set = set(range(y.shape[0]))\n",
        "    for test_idx in test_idxs:\n",
        "      mother_set -= set(test_idx)\n",
        "\n",
        "    test_idx = random.sample(list(mother_set), (int) (y.shape[0] / 10))\n",
        "    test_idx = sorted(test_idx)\n",
        "\n",
        "    train_idx = list(set(range(y.shape[0])) - set(test_idx))\n",
        "    train_idx = sorted(train_idx)\n",
        "\n",
        "    train_idxs.append(train_idx)\n",
        "    test_idxs.append(test_idx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99479507-4875-42a6-ff72-7e66012c56f3",
        "id": "EK6U1QTu_KTW"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train: (3275, 30, 6)\n",
            "X_test: (363, 30, 6)\n",
            "y_train: (3275,)\n",
            "y_test: (363,)\n",
            "Epoch 1/2\n",
            "52/52 [==============================] - 5s 22ms/step - loss: 0.1398 - binary_accuracy: 0.9499 - val_loss: 0.0193 - val_binary_accuracy: 0.9945\n",
            "Epoch 2/2\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0245 - binary_accuracy: 0.9966 - val_loss: 0.0088 - val_binary_accuracy: 0.9945\n",
            "12/12 [==============================] - 0s 3ms/step\n",
            "12/12 [==============================] - 0s 6ms/step\n",
            "[0] Accuracy: 99.45 %.\n",
            "[0] Precision: 100.00 %.\n",
            "[0] Recall: 98.91 %.\n",
            "[0] F1: 99.45 %.\n",
            "X_train: (3275, 30, 6)\n",
            "X_test: (363, 30, 6)\n",
            "y_train: (3275,)\n",
            "y_test: (363,)\n",
            "Epoch 1/2\n",
            "52/52 [==============================] - 2s 11ms/step - loss: 0.1303 - binary_accuracy: 0.9533 - val_loss: 0.0224 - val_binary_accuracy: 0.9945\n",
            "Epoch 2/2\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.0218 - binary_accuracy: 0.9963 - val_loss: 0.0063 - val_binary_accuracy: 0.9972\n",
            "12/12 [==============================] - 0s 2ms/step\n",
            "12/12 [==============================] - 0s 2ms/step\n",
            "[1] Accuracy: 99.72 %.\n",
            "[1] Precision: 100.00 %.\n",
            "[1] Recall: 99.50 %.\n",
            "[1] F1: 99.75 %.\n",
            "X_train: (3275, 30, 6)\n",
            "X_test: (363, 30, 6)\n",
            "y_train: (3275,)\n",
            "y_test: (363,)\n",
            "Epoch 1/2\n",
            "52/52 [==============================] - 2s 10ms/step - loss: 0.1298 - binary_accuracy: 0.9579 - val_loss: 0.0468 - val_binary_accuracy: 0.9890\n",
            "Epoch 2/2\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.0200 - binary_accuracy: 0.9963 - val_loss: 0.0233 - val_binary_accuracy: 0.9972\n",
            "12/12 [==============================] - 0s 2ms/step\n",
            "12/12 [==============================] - 0s 2ms/step\n",
            "[2] Accuracy: 99.72 %.\n",
            "[2] Precision: 100.00 %.\n",
            "[2] Recall: 99.45 %.\n",
            "[2] F1: 99.72 %.\n",
            "X_train: (3275, 30, 6)\n",
            "X_test: (363, 30, 6)\n",
            "y_train: (3275,)\n",
            "y_test: (363,)\n",
            "Epoch 1/2\n",
            "52/52 [==============================] - 2s 17ms/step - loss: 0.1404 - binary_accuracy: 0.9496 - val_loss: 0.0251 - val_binary_accuracy: 0.9972\n",
            "Epoch 2/2\n",
            "52/52 [==============================] - 0s 9ms/step - loss: 0.0222 - binary_accuracy: 0.9969 - val_loss: 0.0230 - val_binary_accuracy: 0.9972\n",
            "12/12 [==============================] - 0s 2ms/step\n",
            "12/12 [==============================] - 0s 2ms/step\n",
            "[3] Accuracy: 99.72 %.\n",
            "[3] Precision: 100.00 %.\n",
            "[3] Recall: 99.38 %.\n",
            "[3] F1: 99.69 %.\n",
            "X_train: (3275, 30, 6)\n",
            "X_test: (363, 30, 6)\n",
            "y_train: (3275,)\n",
            "y_test: (363,)\n",
            "Epoch 1/2\n",
            "52/52 [==============================] - 2s 10ms/step - loss: 0.1347 - binary_accuracy: 0.9487 - val_loss: 0.0023 - val_binary_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "52/52 [==============================] - 0s 7ms/step - loss: 0.0239 - binary_accuracy: 0.9960 - val_loss: 6.0465e-04 - val_binary_accuracy: 1.0000\n",
            "12/12 [==============================] - 0s 2ms/step\n",
            "12/12 [==============================] - 0s 2ms/step\n",
            "[4] Accuracy: 100.00 %.\n",
            "[4] Precision: 100.00 %.\n",
            "[4] Recall: 100.00 %.\n",
            "[4] F1: 100.00 %.\n",
            "X_train: (3275, 30, 6)\n",
            "X_test: (363, 30, 6)\n",
            "y_train: (3275,)\n",
            "y_test: (363,)\n",
            "Epoch 1/2\n",
            "52/52 [==============================] - 2s 10ms/step - loss: 0.1239 - binary_accuracy: 0.9594 - val_loss: 0.1058 - val_binary_accuracy: 0.9835\n",
            "Epoch 2/2\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.0155 - binary_accuracy: 0.9979 - val_loss: 0.0885 - val_binary_accuracy: 0.9890\n",
            "12/12 [==============================] - 0s 2ms/step\n",
            "12/12 [==============================] - 0s 2ms/step\n",
            "[5] Accuracy: 98.90 %.\n",
            "[5] Precision: 100.00 %.\n",
            "[5] Recall: 97.75 %.\n",
            "[5] F1: 98.86 %.\n",
            "X_train: (3275, 30, 6)\n",
            "X_test: (363, 30, 6)\n",
            "y_train: (3275,)\n",
            "y_test: (363,)\n",
            "Epoch 1/2\n",
            "52/52 [==============================] - 2s 10ms/step - loss: 0.1248 - binary_accuracy: 0.9536 - val_loss: 0.0870 - val_binary_accuracy: 0.9862\n",
            "Epoch 2/2\n",
            "52/52 [==============================] - 0s 7ms/step - loss: 0.0218 - binary_accuracy: 0.9969 - val_loss: 0.0520 - val_binary_accuracy: 0.9862\n",
            "12/12 [==============================] - 0s 3ms/step\n",
            "12/12 [==============================] - 0s 3ms/step\n",
            "[6] Accuracy: 98.62 %.\n",
            "[6] Precision: 100.00 %.\n",
            "[6] Recall: 97.35 %.\n",
            "[6] F1: 98.66 %.\n",
            "X_train: (3275, 30, 6)\n",
            "X_test: (363, 30, 6)\n",
            "y_train: (3275,)\n",
            "y_test: (363,)\n",
            "Epoch 1/2\n",
            "52/52 [==============================] - 2s 11ms/step - loss: 0.1256 - binary_accuracy: 0.9603 - val_loss: 9.2820e-04 - val_binary_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "52/52 [==============================] - 0s 7ms/step - loss: 0.0257 - binary_accuracy: 0.9969 - val_loss: 0.0013 - val_binary_accuracy: 1.0000\n",
            "12/12 [==============================] - 0s 2ms/step\n",
            "12/12 [==============================] - 0s 2ms/step\n",
            "[7] Accuracy: 100.00 %.\n",
            "[7] Precision: 100.00 %.\n",
            "[7] Recall: 100.00 %.\n",
            "[7] F1: 100.00 %.\n",
            "X_train: (3275, 30, 6)\n",
            "X_test: (363, 30, 6)\n",
            "y_train: (3275,)\n",
            "y_test: (363,)\n",
            "Epoch 1/2\n",
            "52/52 [==============================] - 2s 10ms/step - loss: 0.1338 - binary_accuracy: 0.9551 - val_loss: 0.0421 - val_binary_accuracy: 0.9917\n",
            "Epoch 2/2\n",
            "52/52 [==============================] - 0s 7ms/step - loss: 0.0210 - binary_accuracy: 0.9973 - val_loss: 0.0258 - val_binary_accuracy: 0.9972\n",
            "12/12 [==============================] - 0s 2ms/step\n",
            "12/12 [==============================] - 0s 2ms/step\n",
            "[8] Accuracy: 99.72 %.\n",
            "[8] Precision: 100.00 %.\n",
            "[8] Recall: 99.47 %.\n",
            "[8] F1: 99.73 %.\n",
            "X_train: (3275, 30, 6)\n",
            "X_test: (363, 30, 6)\n",
            "y_train: (3275,)\n",
            "y_test: (363,)\n",
            "Epoch 1/2\n",
            "52/52 [==============================] - 2s 10ms/step - loss: 0.1531 - binary_accuracy: 0.9450 - val_loss: 0.0013 - val_binary_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "52/52 [==============================] - 0s 7ms/step - loss: 0.0261 - binary_accuracy: 0.9954 - val_loss: 3.5328e-04 - val_binary_accuracy: 1.0000\n",
            "12/12 [==============================] - 0s 2ms/step\n",
            "12/12 [==============================] - 0s 2ms/step\n",
            "[9] Accuracy: 100.00 %.\n",
            "[9] Precision: 100.00 %.\n",
            "[9] Recall: 100.00 %.\n",
            "[9] F1: 100.00 %.\n"
          ]
        }
      ],
      "source": [
        "from tensorflow import keras\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "accs = []\n",
        "precisions = []\n",
        "recalls = []\n",
        "f1s = []\n",
        "\n",
        "for fold_num, (train_idx, test_idx) in enumerate(zip(train_idxs, test_idxs)):\n",
        "  X_train, X_test = X[train_idx], X[test_idx]\n",
        "  y_train, y_test = y[train_idx], y[test_idx]\n",
        "\n",
        "  print(f'X_train: {X_train.shape}')\n",
        "  print(f'X_test: {X_test.shape}')\n",
        "  print(f'y_train: {y_train.shape}')\n",
        "  print(f'y_test: {y_test.shape}')\n",
        "\n",
        "  model = keras.models.Sequential([\n",
        "      keras.layers.InputLayer(input_shape=(30, 6)),\n",
        "      keras.layers.BatchNormalization(),\n",
        "      keras.layers.Conv1D(\n",
        "          filters=32, kernel_size=8, padding = \"same\",\n",
        "          activation = keras.activations.relu,\n",
        "          kernel_initializer=keras.initializers.HeNormal(seed=1004),\n",
        "      ),\n",
        "      keras.layers.MaxPooling1D(\n",
        "          pool_size=2\n",
        "      ),\n",
        "      keras.layers.Flatten(),\n",
        "      keras.layers.Dense(\n",
        "          units = 64,\n",
        "          activation = keras.activations.relu,\n",
        "          kernel_initializer = keras.initializers.HeNormal(seed=1004)\n",
        "      ),\n",
        "      keras.layers.Dropout(\n",
        "          rate = .5,\n",
        "      ),\n",
        "      keras.layers.Dense(\n",
        "          units = 1,\n",
        "          activation=keras.activations.sigmoid,\n",
        "          kernel_initializer=keras.initializers.GlorotUniform(seed=1004)\n",
        "      )\n",
        "  ])\n",
        "\n",
        "  model.compile(\n",
        "    loss=keras.losses.BinaryCrossentropy (),\n",
        "    optimizer=keras.optimizers.Adam(),\n",
        "    metrics=[\n",
        "            keras.metrics.BinaryAccuracy(),\n",
        "    ]\n",
        "  )\n",
        "\n",
        "  model.fit(\n",
        "      x=X_train,\n",
        "      y=y_train,\n",
        "      validation_data=(X_test, y_test),\n",
        "      batch_size=64,\n",
        "      epochs=2,\n",
        "  )\n",
        "\n",
        "  y_pred = np.argmax(model.predict(X_test), axis=1)\n",
        "  y_pred = np.round(model.predict(X_test))\n",
        "  acc, precision, recall, f1 = accuracy_score(y_test, y_pred), precision_score(y_test, y_pred), recall_score(y_test, y_pred), f1_score(y_test, y_pred)\n",
        "\n",
        "  print(f'[{fold_num}] Accuracy: {acc * 100:.2f} %.')\n",
        "  print(f'[{fold_num}] Precision: {precision * 100:.2f} %.')\n",
        "  print(f'[{fold_num}] Recall: {recall * 100:.2f} %.')\n",
        "  print(f'[{fold_num}] F1: {f1 * 100:.2f} %.')\n",
        "\n",
        "  accs.append(acc)\n",
        "  precisions.append(precision)\n",
        "  recalls.append(recall)\n",
        "  f1s.append(f1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y_8AAULa_KTX"
      },
      "source": [
        "#### Evaluation\n",
        "Now with K-Fold validation data, evaluate our model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c4ac356-077d-438d-f50e-ddf108797e2d",
        "id": "qY9tGQA8_KTX"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy | Precision | Recall | F1\n",
            "[0] 99.45 %, 100.00 %, 100.00 %, 99.45 %\n",
            "[1] 99.72 %, 100.00 %, 100.00 %, 99.75 %\n",
            "[2] 99.72 %, 100.00 %, 100.00 %, 99.72 %\n",
            "[3] 99.72 %, 100.00 %, 100.00 %, 99.69 %\n",
            "[4] 100.00 %, 100.00 %, 100.00 %, 100.00 %\n",
            "[5] 98.90 %, 100.00 %, 100.00 %, 98.86 %\n",
            "[6] 98.62 %, 100.00 %, 100.00 %, 98.66 %\n",
            "[7] 100.00 %, 100.00 %, 100.00 %, 100.00 %\n",
            "[8] 99.72 %, 100.00 %, 100.00 %, 99.73 %\n",
            "[9] 100.00 %, 100.00 %, 100.00 %, 100.00 %\n",
            "[Total] 99.59 %, 100.00 %, 100.00 %, 99.59 %\n"
          ]
        }
      ],
      "source": [
        "tot_acc, tot_precision, tot_recall, tot_f1 = 0.0, 0.0, 0.0, 0.0\n",
        "cnt = 0\n",
        "\n",
        "print(\"Accuracy | Precision | Recall | F1\")\n",
        "\n",
        "for fold_num, (acc, precision, reacll, f1) in enumerate(zip(accs, precisions, recalls, f1s)):\n",
        "  cnt += 1\n",
        "  tot_acc += acc\n",
        "  tot_precision += precision\n",
        "  tot_recall += recall\n",
        "  tot_f1 += f1\n",
        "\n",
        "  print(f\"[{fold_num}] {acc * 100:.2f} %, {precision * 100:.2f} %, {recall * 100:.2f} %, {f1 * 100:.2f} %\")\n",
        "\n",
        "tot_acc /= cnt\n",
        "tot_precision /= cnt\n",
        "tot_recall /= cnt\n",
        "tot_f1 /= cnt\n",
        "\n",
        "print(f\"[Total] {tot_acc * 100:.2f} %, {tot_precision * 100:.2f} %, {tot_recall * 100:.2f} %, {tot_f1 * 100:.2f} %\")"
      ]
    }
  ]
}